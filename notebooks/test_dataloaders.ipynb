{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Dataloaders\n",
    "\n",
    "this notebook is to test the text-dataloaders for the translation task for the transformer model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pritishmishra/anaconda3/envs/transformer_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# adding project root directory to the sys path\n",
    "project_root = os.path.abspath(os.path.join(\n",
    "    os.getcwd(), '..'))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from src.data.text_dataloader import TextDataLoader\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the downloaded datasets. \n",
    "## here, we will use the bert-base-multilingual-uncased tokenizer for the tokenization of the text data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['No, no, not so fast.\\n', ', eject!\\n', \"I'm Dr. Messa.\\n\", 'So we notify the cops about big ticket sales and we even keep half a dozen Ukrainian ex-naval commandos in a van outside, just in case it all kicks off.\\n', 'receiving what their Lord has given them, for they had been virtuous aforetime.\\n', \"Default folder to use for the '--add' and '--extract' commands\\n\", 'Hey, how are you? Beautiful day.\\n', 'Dengue is a tropical virus carried by the Aedes aegypti mosquito with no known cure. According to the World Health Organization, about 40 percent of the world’s population is at risk from dengue.\\n', 'Show right margin\\n', '%s: not enough free space\\n'] \n",
      "\n",
      "['तुम इतनी आसानी से छूट नहीं सकते.\\n', ', बेदखल!\\n', 'Messa हूँ.\\n', 'तोहमबड़ीटिकटोंकीबिक्रीकेबारे मेंपुलिस सूचित... / मैं ... और हम भी रखना आधा दर्जन यूक्रेनी पूर्व नौसेना कमांडो...\\n', 'जो कुछ उनके रब ने उन्हें दिया, वे उसे ले रहे होंगे। निस्संदेह वे इससे पहले उत्तमकारों में से थे\\n', '--add और --extract कमान्ड में उपयोग हेतु डिफ़ॉल्ट फ़ोल्डर\\n', 'सुहाना दिन है।\\n', '5 प्रतिशत कम हो गई, यानि डेंगू के कारण अस्पताल में भर्ती होने की आशंका में करीब 67 प्रतिशत कमी आई।\\n', 'दिखाएँ दायाँ\\n', '%s: पर्याप्त मुक्त स्थान नहींFree\\n'] \n",
      "\n",
      "['Other, Private Use\\n', '[SCREAMING]\\n', 'Spouse\\n', 'I will never salute you!\\n', 'and the stars and the trees bow themselves;\\n', '_Download Messages for Offline Usage\\n', 'Nor is it the speech of a soothsayer; how little do you ponder!\\n', 'A folder named \"{1}\" already exists. Please use a different name.\\n', \"The application '%s' could not be created\\n\", 'Believers, it is unlawful for you to inherit women forcefully, neither bar them, in order that you go off with part of what you have given them, except when they commit a clear indecency. Live with them honorably. If you hate them, it may be that you hate something which Allah has set in it much good.\\n'] \n",
      "\n",
      "['अन्य, निज़ी उपयोग\\n', 'ऊबड़ .\\n', 'जीवनसाथी\\n', '- तुम एक कमांडर कभी नहीं होगा!\\n', 'और तारे और वृक्ष सजदा करते है;\\n', 'ऑफ़लाइन प्रयोग के लिए संदेश डाउनलोड करें (_D)\\n', 'और न किसी काहिन की (ख्याली) बात है तुम लोग तो बहुत कम ग़ौर करते हो\\n', '\"{1}\" नाम से फ़ोल्डर पहले से उपस्थित है. कृपया दूसरे नाम का उपयोग करें.\\n', \"अनुप्रयोग '%s' के लिए इस्तेमाल किया जा के लिए तैयार है.\\n\", 'ऐ ईमान लानेवालो! तुम्हारे लिए वैध नहीं कि स्त्रियों के माल के ज़बरदस्ती वारिस बन बैठो, और न यह वैध है कि उन्हें इसलिए रोको और तंग करो कि जो कुछ तुमने उन्हें दिया है, उसमें से कुछ ले उड़ो। परन्तु यदि वे खुले रूप में अशिष्ट कर्म कर बैठे तो दूसरी बात है। और उनके साथ भले तरीक़े से रहो-सहो। फिर यदि वे तुम्हें पसन्द न हों, तो सम्भव है कि एक चीज़ तुम्हें पसन्द न हो और अल्लाह उसमें बहुत कुछ भलाई रख दे\\n'] \n",
      "\n",
      "['Give shots of injections or pills, but he must be alright soon.\\n', 'They said, “O Shuaib, we do not understand much of what you say, and we see that you are weak among us. Were it not for your tribe, we would have stoned you. You are of no value to us.”\\n', '- Yeah.\\n', 'If evil befalls him he is perturbed;\\n', '♪ BE FOREVER BOUND\\n', \"Trying to movemail a non-mbox source '%s'\\n\", 'Image histogram adjust levels plugin for digiKam\\n', 'She took every able-bodied man and went to kill the Forest Spirit.\\n', \"My mother's from Sweden.\\n\", \"Say: Shall I tell you what is better than these? For those who guard (against evil) are gardens with their Lord, beneath which rivers flow, to abide in them, and pure mates and Allah's pleasure; and Allah sees the servants.\\n\"] \n",
      "\n",
      "['सुई लगाओ या गोली खिलाओ लेकिन इसे जल्दी से ठीक करो.\\n', 'और वह लोग कहने लगे ऐ शुएब जो बाते तुम कहते हो उनमें से अक्सर तो हमारी समझ ही में नहीं आयी और इसमें तो शक नहीं कि हम तुम्हें अपने लोगों में बहुत कमज़ोर समझते है और अगर तुम्हारा क़बीला न होता तो हम तुम को (कब का) संगसार कर चुके होते और तुम तो हम पर किसी तरह ग़ालिब नहीं आ सकते\\n', '- हाँ.\\n', 'जि उसे तकलीफ़ पहुँचती है तो घबरा उठता है,\\n', '♪हमेशाके लिएबाध्यहोने\\n', \"एक गैर-mbox स्रोत '%s' में डाक भेजने की कोशिश\\n\", 'डिज़ीकैम के लिए इमेज़ हिस्टोग्राम एडजस्ट लेवल्स प्लगइन\\n', '- लेडी Eboshi कहां है? हर आदमी है जो स्थानांतरित कर सकता लिया और हिरण भगवान को मारने के लिए चला गया.\\n', 'वो मेरी माँ है.\\n', '(ऐ रसूल) उन लोगों से कह दो कि क्या मैं तुमको उन सब चीज़ों से बेहतर चीज़ बता दूं (अच्छा सुनो) जिन लोगों ने परहेज़गारी इख्तेयार की उनके लिए उनके परवरदिगार के यहॉ (बेहिश्त) के वह बाग़ात हैं जिनके नीचे नहरें जारी हैं (और वह) हमेशा उसमें रहेंगे और उसके अलावा उनके लिए साफ सुथरी बीवियॉ हैं और (सबसे बढ़कर) ख़ुदा की ख़ुशनूदी है और ख़ुदा (अपने) उन बन्दों को खूब देख रहा हे जो दुआऐं मॉगा करते हैं\\n'] \n",
      "\n",
      "Total number of samples in the source dev data: 2000 \n",
      "\n",
      "Total number of samples in the target dev data: 2000 \n",
      "\n",
      "Total number of samples in the source train data: 534319 \n",
      "\n",
      "Total number of samples in the target train data: 534319 \n",
      "\n",
      "Total number of samples in the source test data: 2000 \n",
      "\n",
      "Total number of samples in the target test data: 2000 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "src_val_data = os.path.join(project_root, 'Datasets', 'raw', 'en-hi', 'opus.en-hi-dev.en')\n",
    "tgt_val_data = os.path.join(project_root, 'Datasets', 'raw', 'en-hi', 'opus.en-hi-dev.hi')\n",
    "src_train_data = os.path.join(project_root, 'Datasets', 'raw', 'en-hi', 'opus.en-hi-train.en')\n",
    "tgt_train_data = os.path.join(project_root, 'Datasets', 'raw', 'en-hi', 'opus.en-hi-train.hi')\n",
    "src_test_data = os.path.join(project_root, 'Datasets', 'raw', 'en-hi', 'opus.en-hi-test.en')\n",
    "tgt_test_data = os.path.join(project_root, 'Datasets', 'raw', 'en-hi', 'opus.en-hi-test.hi')\n",
    "\n",
    "# print the first 10 lines of the source and target data for the dev, train and test data. \n",
    "with open(src_val_data, 'r') as f:\n",
    "    print(f.readlines()[:10], \"\\n\")\n",
    "\n",
    "with open(tgt_val_data, 'r') as f:\n",
    "    print(f.readlines()[:10], \"\\n\")\n",
    "\n",
    "with open(src_train_data, 'r') as f:\n",
    "    print(f.readlines()[:10], \"\\n\")\n",
    "\n",
    "with open(tgt_train_data, 'r') as f:\n",
    "    print(f.readlines()[:10], \"\\n\")\n",
    "\n",
    "with open(src_test_data, 'r') as f:\n",
    "    print(f.readlines()[:10], \"\\n\")\n",
    "\n",
    "with open(tgt_test_data, 'r') as f:\n",
    "    print(f.readlines()[:10], \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# print the total number of samples in the source and target data for the dev, train and test data. \n",
    "print(f\"Total number of samples in the source dev data: {len(open(src_val_data, 'r').readlines())}\", \"\\n\")\n",
    "print(f\"Total number of samples in the target dev data: {len(open(tgt_val_data, 'r').readlines())}\", \"\\n\")\n",
    "print(f\"Total number of samples in the source train data: {len(open(src_train_data, 'r').readlines())}\", \"\\n\")\n",
    "print(f\"Total number of samples in the target train data: {len(open(tgt_train_data, 'r').readlines())}\", \"\\n\")\n",
    "print(f\"Total number of samples in the source test data: {len(open(src_test_data, 'r').readlines())}\", \"\\n\")\n",
    "print(f\"Total number of samples in the target test data: {len(open(tgt_test_data, 'r').readlines())}\", \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize and test the test the text dataloader. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the source input ids: torch.Size([32, 512]) \n",
      "\n",
      "Shape of the source attention mask: torch.Size([32, 512]) \n",
      "\n",
      "Shape of the target input ids: torch.Size([32, 512]) \n",
      "\n",
      "Shape of the target attention mask: torch.Size([32, 512]) \n",
      "\n",
      "\n",
      "First few samples of the source input ids:\n",
      "tensor([[101, 156, 102,  ...,   0,   0,   0],\n",
      "        [101, 161, 102,  ...,   0,   0,   0],\n",
      "        [101, 154, 102,  ...,   0,   0,   0]]) \n",
      "\n",
      "\n",
      "First few samples of the target input ids:\n",
      "tensor([[101, 156, 102,  ...,   0,   0,   0],\n",
      "        [101, 161, 102,  ...,   0,   0,   0],\n",
      "        [101, 154, 102,  ...,   0,   0,   0]]) \n",
      "\n",
      "\n",
      "First few samples of the source attention mask:\n",
      "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]) \n",
      "\n",
      "\n",
      "First few samples of the target attention mask:\n",
      "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]) \n",
      "\n",
      "\n",
      "First few samples of the source input sequences:\n",
      "Sample 1: [CLS] n [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]...\n",
      "Sample 2: [CLS] s [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]...\n",
      "Sample 3: [CLS] l [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]...\n",
      "\n",
      "First few samples of the target input sequences:\n",
      "Sample 1: [CLS] n [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]...\n",
      "Sample 2: [CLS] s [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]...\n",
      "Sample 3: [CLS] l [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]...\n"
     ]
    }
   ],
   "source": [
    "# initialize the text dataloader for the train data\n",
    "text_train_dataloader = TextDataLoader(src_train_data, tgt_train_data, max_len=512)\n",
    "\n",
    "# initialize the text dataloader for the validation data\n",
    "text_val_dataloader = TextDataLoader(src_val_data, tgt_val_data, max_len=512)\n",
    "\n",
    "# initialize the text dataloader for the test data\n",
    "text_test_dataloader = TextDataLoader(src_test_data, tgt_test_data, max_len=512)\n",
    "\n",
    "# load the training data\n",
    "train_dataloader = text_train_dataloader.load_data()\n",
    "\n",
    "# load the validation data\n",
    "val_dataloader = text_val_dataloader.load_data()\n",
    "\n",
    "# load the testing data\n",
    "test_dataloader = text_test_dataloader.load_data()\n",
    "\n",
    "# get the first batch of the training data to inspect\n",
    "batch = next(iter(train_dataloader))\n",
    "src_train_input_ids, src_train_attention_mask, train_tgt_input_ids, train_tgt_attention_mask = batch\n",
    "\n",
    "# print the shapes of the source and target training data\n",
    "print(f\"Shape of the source input ids: {src_train_input_ids.shape}\", \"\\n\")\n",
    "print(f\"Shape of the source attention mask: {src_train_attention_mask.shape}\", \"\\n\")\n",
    "print(f\"Shape of the target input ids: {train_tgt_input_ids.shape}\", \"\\n\")\n",
    "print(f\"Shape of the target attention mask: {train_tgt_attention_mask.shape}\", \"\\n\")\n",
    "\n",
    "# print the first few samples of the source and target training data\n",
    "print(f\"\\nFirst few samples of the source input ids:\\n{src_train_input_ids[:3]}\", \"\\n\")\n",
    "print(f\"\\nFirst few samples of the target input ids:\\n{train_tgt_input_ids[:3]}\", \"\\n\")\n",
    "\n",
    "# print the first few samples of the source and target attention masks of the training data\n",
    "print(f\"\\nFirst few samples of the source attention mask:\\n{src_train_attention_mask[:3]}\", \"\\n\")\n",
    "print(f\"\\nFirst few samples of the target attention mask:\\n{train_tgt_attention_mask[:3]}\", \"\\n\")\n",
    "\n",
    "# print the first few samples of the source and target input sequences in the training data\n",
    "print(\"\\nFirst few samples of the source input sequences:\")\n",
    "for i in range(3):  # Show first 3 sequences\n",
    "    tokens = text_train_dataloader.tokenizer.convert_ids_to_tokens(src_train_input_ids[i])\n",
    "    print(f\"Sample {i+1}: {' '.join(tokens[:10])}...\")  # Show first 10 tokens\n",
    "\n",
    "print(\"\\nFirst few samples of the target input sequences:\")\n",
    "for i in range(3):  # Show first 3 sequences\n",
    "    tokens = text_train_dataloader.tokenizer.convert_ids_to_tokens(train_tgt_input_ids[i])\n",
    "    print(f\"Sample {i+1}: {' '.join(tokens[:10])}...\")  # Show first 10 tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inspecting the validation dataloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the source input ids: torch.Size([32, 512]) \n",
      "\n",
      "Shape of the source attention mask: torch.Size([32, 512]) \n",
      "\n",
      "Shape of the target input ids: torch.Size([32, 512]) \n",
      "\n",
      "Shape of the target attention mask: torch.Size([32, 512]) \n",
      "\n",
      "\n",
      "First few samples of the source input ids:\n",
      "tensor([[101, 165, 102,  ...,   0,   0,   0],\n",
      "        [101, 157, 102,  ...,   0,   0,   0],\n",
      "        [101, 146, 102,  ...,   0,   0,   0]]) \n",
      "\n",
      "\n",
      "First few samples of the target input ids:\n",
      "tensor([[101, 165, 102,  ...,   0,   0,   0],\n",
      "        [101, 157, 102,  ...,   0,   0,   0],\n",
      "        [101, 146, 102,  ...,   0,   0,   0]]) \n",
      "\n",
      "\n",
      "First few samples of the source attention mask:\n",
      "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]) \n",
      "\n",
      "\n",
      "First few samples of the target attention mask:\n",
      "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]) \n",
      "\n",
      "\n",
      "First few samples of the source input sequences:\n",
      "Sample 1: [CLS] w [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]...\n",
      "Sample 2: [CLS] o [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]...\n",
      "Sample 3: [CLS] d [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]...\n",
      "\n",
      "First few samples of the target input sequences:\n",
      "Sample 1: [CLS] w [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]...\n",
      "Sample 2: [CLS] o [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]...\n",
      "Sample 3: [CLS] d [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]...\n"
     ]
    }
   ],
   "source": [
    "# get the first batch of the validation data to inspect\n",
    "batch = next(iter(val_dataloader))\n",
    "src_val_input_ids, src_val_attention_mask, val_tgt_input_ids, val_tgt_attention_mask = batch\n",
    "\n",
    "# print the shapes of the source and target validation data\n",
    "print(f\"Shape of the source input ids: {src_val_input_ids.shape}\", \"\\n\")\n",
    "print(f\"Shape of the source attention mask: {src_val_attention_mask.shape}\", \"\\n\")\n",
    "print(f\"Shape of the target input ids: {val_tgt_input_ids.shape}\", \"\\n\")\n",
    "print(f\"Shape of the target attention mask: {val_tgt_attention_mask.shape}\", \"\\n\")\n",
    "\n",
    "# print the first few samples of the source and target validation data\n",
    "print(f\"\\nFirst few samples of the source input ids:\\n{src_val_input_ids[:3]}\", \"\\n\")\n",
    "print(f\"\\nFirst few samples of the target input ids:\\n{val_tgt_input_ids[:3]}\", \"\\n\")\n",
    "\n",
    "# print the first few samples of the source and target attention masks of the validation data\n",
    "print(f\"\\nFirst few samples of the source attention mask:\\n{src_val_attention_mask[:3]}\", \"\\n\")\n",
    "print(f\"\\nFirst few samples of the target attention mask:\\n{val_tgt_attention_mask[:3]}\", \"\\n\")\n",
    "\n",
    "# print the total number of batches in the validation data\n",
    "\n",
    "\n",
    "# print the first few samples of the source and target input sequences in the validation data\n",
    "print(\"\\nFirst few samples of the source input sequences:\")\n",
    "for i in range(3):  # Show first 3 sequences\n",
    "    tokens = text_val_dataloader.tokenizer.convert_ids_to_tokens(src_val_input_ids[i])\n",
    "    print(f\"Sample {i+1}: {' '.join(tokens[:10])}...\")  # Show first 10 tokens\n",
    "\n",
    "print(\"\\nFirst few samples of the target input sequences:\")\n",
    "for i in range(3):  # Show first 3 sequences\n",
    "    tokens = text_val_dataloader.tokenizer.convert_ids_to_tokens(val_tgt_input_ids[i])\n",
    "    print(f\"Sample {i+1}: {' '.join(tokens[:10])}...\")  # Show first 10 tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inspecting the test dataloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the source input ids: torch.Size([32, 512]) \n",
      "\n",
      "Shape of the source attention mask: torch.Size([32, 512]) \n",
      "\n",
      "Shape of the target input ids: torch.Size([32, 512]) \n",
      "\n",
      "Shape of the target attention mask: torch.Size([32, 512]) \n",
      "\n",
      "\n",
      "First few samples of the source input ids:\n",
      "tensor([[101, 120, 102,  ...,   0,   0,   0],\n",
      "        [101, 160, 102,  ...,   0,   0,   0],\n",
      "        [101, 157, 102,  ...,   0,   0,   0]]) \n",
      "\n",
      "\n",
      "First few samples of the target input ids:\n",
      "tensor([[101, 120, 102,  ...,   0,   0,   0],\n",
      "        [101, 160, 102,  ...,   0,   0,   0],\n",
      "        [101, 157, 102,  ...,   0,   0,   0]]) \n",
      "\n",
      "\n",
      "First few samples of the source attention mask:\n",
      "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]) \n",
      "\n",
      "\n",
      "First few samples of the target attention mask:\n",
      "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]) \n",
      "\n",
      "\n",
      "First few samples of the source input sequences:\n",
      "Sample 1: [CLS] / [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]...\n",
      "Sample 2: [CLS] r [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]...\n",
      "Sample 3: [CLS] o [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]...\n",
      "\n",
      "First few samples of the target input sequences:\n",
      "Sample 1: [CLS] / [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]...\n",
      "Sample 2: [CLS] r [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]...\n",
      "Sample 3: [CLS] o [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]...\n"
     ]
    }
   ],
   "source": [
    "# get the first batch of the training data to inspect\n",
    "batch = next(iter(train_dataloader))\n",
    "src_train_input_ids, src_train_attention_mask, train_tgt_input_ids, train_tgt_attention_mask = batch\n",
    "\n",
    "# print the shapes of the source and target training data\n",
    "print(f\"Shape of the source input ids: {src_train_input_ids.shape}\", \"\\n\")\n",
    "print(f\"Shape of the source attention mask: {src_train_attention_mask.shape}\", \"\\n\")\n",
    "print(f\"Shape of the target input ids: {train_tgt_input_ids.shape}\", \"\\n\")\n",
    "print(f\"Shape of the target attention mask: {train_tgt_attention_mask.shape}\", \"\\n\")\n",
    "\n",
    "# print the first few samples of the source and target training data\n",
    "print(f\"\\nFirst few samples of the source input ids:\\n{src_train_input_ids[:3]}\", \"\\n\")\n",
    "print(f\"\\nFirst few samples of the target input ids:\\n{train_tgt_input_ids[:3]}\", \"\\n\")\n",
    "\n",
    "# print the first few samples of the source and target attention masks of the training data\n",
    "print(f\"\\nFirst few samples of the source attention mask:\\n{src_train_attention_mask[:3]}\", \"\\n\")\n",
    "print(f\"\\nFirst few samples of the target attention mask:\\n{train_tgt_attention_mask[:3]}\", \"\\n\")\n",
    "\n",
    "# print the first few samples of the source and target input sequences in the training data\n",
    "print(\"\\nFirst few samples of the source input sequences:\")\n",
    "for i in range(3):  # Show first 3 sequences\n",
    "    tokens = text_train_dataloader.tokenizer.convert_ids_to_tokens(src_train_input_ids[i])\n",
    "    print(f\"Sample {i+1}: {' '.join(tokens[:10])}...\")  # Show first 10 tokens\n",
    "\n",
    "print(\"\\nFirst few samples of the target input sequences:\")\n",
    "for i in range(3):  # Show first 3 sequences\n",
    "    tokens = text_train_dataloader.tokenizer.convert_ids_to_tokens(train_tgt_input_ids[i])\n",
    "    print(f\"Sample {i+1}: {' '.join(tokens[:10])}...\")  # Show first 10 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total vocabulary size: 24\n",
      "English vocabulary size: 24\n",
      "Hindi vocabulary size: 24\n",
      "\n",
      "Sample English tokens:\n",
      "['a', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'l', 'm']\n",
      "\n",
      "Sample Hindi tokens:\n",
      "['a', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'l', 'm']\n"
     ]
    }
   ],
   "source": [
    "# Compute vocabulary size for English and Hindi sentences\n",
    "\n",
    "# Function to get unique tokens from a dataset\n",
    "def get_unique_tokens(dataloader):\n",
    "    unique_tokens = set()\n",
    "    for batch in dataloader:\n",
    "        src_input_ids, _, tgt_input_ids, _ = batch\n",
    "        unique_tokens.update(src_input_ids.unique().tolist())\n",
    "        unique_tokens.update(tgt_input_ids.unique().tolist())\n",
    "    return unique_tokens\n",
    "\n",
    "# Get unique tokens for training and validation sets\n",
    "train_tokens = get_unique_tokens(train_dataloader)\n",
    "val_tokens = get_unique_tokens(val_dataloader)\n",
    "\n",
    "# Combine unique tokens from both sets\n",
    "all_tokens = train_tokens.union(val_tokens)\n",
    "\n",
    "# Remove special tokens (assuming IDs 0-3 are special tokens like PAD, UNK, etc.)\n",
    "vocab_tokens = [token for token in all_tokens if token > 3]\n",
    "\n",
    "# Print vocabulary size\n",
    "print(f\"Total vocabulary size: {len(vocab_tokens)}\")\n",
    "\n",
    "# Get vocabulary for source (English) and target (Hindi) separately\n",
    "src_vocab = set()\n",
    "tgt_vocab = set()\n",
    "\n",
    "for batch in train_dataloader:\n",
    "    src_input_ids, _, tgt_input_ids, _ = batch\n",
    "    src_vocab.update(src_input_ids.unique().tolist())\n",
    "    tgt_vocab.update(tgt_input_ids.unique().tolist())\n",
    "\n",
    "for batch in val_dataloader:\n",
    "    src_input_ids, _, tgt_input_ids, _ = batch\n",
    "    src_vocab.update(src_input_ids.unique().tolist())\n",
    "    tgt_vocab.update(tgt_input_ids.unique().tolist())\n",
    "\n",
    "# Remove special tokens\n",
    "src_vocab = [token for token in src_vocab if token > 3]\n",
    "tgt_vocab = [token for token in tgt_vocab if token > 3]\n",
    "\n",
    "print(f\"English vocabulary size: {len(src_vocab)}\")\n",
    "print(f\"Hindi vocabulary size: {len(tgt_vocab)}\")\n",
    "\n",
    "# Print some sample tokens\n",
    "print(\"\\nSample English tokens:\")\n",
    "print(text_train_dataloader.tokenizer.convert_ids_to_tokens(src_vocab[:10]))\n",
    "print(\"\\nSample Hindi tokens:\")\n",
    "print(text_train_dataloader.tokenizer.convert_ids_to_tokens(tgt_vocab[:10]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_transformer_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
